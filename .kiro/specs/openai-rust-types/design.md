# Design Document

## Overview

This design outlines the architecture for a Rust workspace that generates strongly-typed request and response structures for the OpenAI API using Progenitor. The solution focuses purely on type generation from OpenAPI specifications, providing a multi-crate workspace with unified dependency management and research-driven configuration optimization.

## Architecture

### Workspace Structure

```
project-root/
├── Cargo.toml                 # Workspace configuration
├── async-openai/              # Submodule for comparison reference
├── scripts/
│   └── extract_openapi.py     # Python script for OpenAPI extraction
├── crates/
│   ├── openai/                # OpenAI-specific crate
│   │   ├── Cargo.toml
│   │   ├── openapi.documented.yml  # Complete OpenAI OpenAPI specification
│   │   ├── openai-chat-completions.yaml  # Extracted chat completions spec
│   │   ├── src/
│   │   │   ├── lib.rs
│   │   │   └── types/         # Generated request/response types
│   │   └── build.rs           # Build script for Progenitor integration
│   └── xtask/                 # Workspace utilities (minimal initially)
│       ├── Cargo.toml
│       └── src/
│           └── main.rs        # Placeholder for future utilities
└── README.md
```

### Dependency Management Strategy

The workspace will use centralized dependency management:

- **Workspace Cargo.toml**: Defines all dependency versions
- **Crate Cargo.toml**: Uses `workspace = true` for shared dependencies
- **Version Consistency**: All crates use identical library versions

## Components and Interfaces

### 1. OpenAI Crate (`crates/openai`)

**Purpose**: Contains generated request/response types for OpenAI API endpoints.

**Key Modules**:
- `types`: Generated request/response structures from Progenitor
- `lib.rs`: Public API exports and module organization

**Public API Design** (Structure determined by Progenitor output):
```rust
// Request types (exact structure TBD based on research)
pub struct ChatCompletionRequest { /* generated by Progenitor */ }
pub struct EmbeddingRequest { /* generated by Progenitor */ }
pub struct ImageGenerationRequest { /* generated by Progenitor */ }

// Response types (exact structure TBD based on research)
pub struct ChatCompletionResponse { /* generated by Progenitor */ }
pub struct EmbeddingResponse { /* generated by Progenitor */ }
pub struct ImageGenerationResponse { /* generated by Progenitor */ }

// Error types (if generated by Progenitor)
// Structure depends on Progenitor configuration
```

### 2. XTask Crate (`crates/xtask`)

**Purpose**: Placeholder for future workspace utilities.

**Initial Implementation**: Minimal structure with potential for future expansion based on actual needs.

### 3. Type Generation Pipeline

**Progenitor Integration**:
- Build script (`build.rs`) in OpenAI crate
- Configuration flags determined through research phase
- Automated regeneration during builds

**Generation Process**:
1. Parse `openapi.documented.yml`
2. Apply research-determined Progenitor configuration flags
3. Generate request/response types only
4. Output types with serde serialization support

## Data Models

### Generated Type Categories

1. **Request Types**: Strongly-typed structs for API requests
   - Structure determined by Progenitor output
   - Required fields enforced at compile-time
   - Optional fields as `Option<T>`
   - Serde serialization support

2. **Response Types**: Deserialization targets for API responses
   - Structure determined by Progenitor output
   - Backward compatibility through optional fields
   - Serde deserialization support
   - Nested structure support

3. **Error Types**: Generated error structures (if any)
   - Structure depends on Progenitor configuration
   - May include API error representations

### Type Structure Research

The exact structure of generated types will be determined through research comparing Progenitor output with async-openai library types. This research will inform:
- Naming conventions
- Field serialization attributes
- Optional field handling
- Nested type organization

## Phased Research and Optimization Strategy

### Phase-Based Approach

**Phase 1: Chat Completions Optimization**
1. **OpenAPI Extraction**: Use Python script to extract chat completions endpoints from complete OpenAPI spec
2. **Initial Generation**: Generate types using default Progenitor settings on extracted spec
3. **Comparison**: Analyze against async-openai submodule chat completion types
4. **Iterative Optimization**: Adjust Progenitor flags to maximize similarity
5. **Documentation**: Record configuration changes and their effects

**Phase 2: Multi-Endpoint Validation**
1. **Expand Extraction**: Add another endpoint (e.g., embeddings) to extracted spec
2. **Preserve Optimization**: Maintain chat completions compatibility while optimizing new endpoint
3. **Cross-Validation**: Ensure configuration works well for multiple endpoints
4. **Refinement**: Fine-tune configuration for broader compatibility

**Phase 3: Full API Generation**
1. **Complete Generation**: Apply optimized configuration to full OpenAPI specification
2. **Validation**: Verify all major endpoints generate compatible types
3. **Final Documentation**: Document complete configuration and rationale

### OpenAPI Extraction Strategy

**Python Script Capabilities**:
- Parse complete openapi.documented.yml
- Extract specific endpoint definitions with all dependencies
- Generate focused OpenAPI files for iterative testing
- Maintain schema references and component definitions

**Extraction Process**:
```python
# Extract chat completions endpoints
# Include: /chat/completions paths, request/response schemas, referenced components
# Output: openai-chat-completions.yaml
```

### Research Comparison Points

- **Type Names**: Struct and field naming conventions
- **Serialization**: JSON field name mapping (`#[serde(rename = "...")]`)
- **Optional Fields**: Usage of `Option<T>` for optional API fields
- **Nested Types**: Organization of complex nested structures
- **Enums**: Handling of API enumeration values
- **Module Organization**: How types are grouped and exported

### Configuration Discovery Process

1. **Baseline Comparison**: Document differences between default Progenitor output and async-openai
2. **Flag Experimentation**: Test individual Progenitor configuration flags
3. **Iterative Refinement**: Combine flags to achieve maximum compatibility
4. **Multi-Endpoint Validation**: Ensure configuration works across different API endpoints
5. **Final Optimization**: Balance compatibility with code quality and maintainability

## Generated Type Characteristics

### Serialization Support

All generated types will include serde support for:
- JSON serialization of request types
- JSON deserialization of response types
- Proper field name mapping to match OpenAI API expectations

### Type Safety Features

- Compile-time validation of required fields
- Optional field representation using `Option<T>`
- Strong typing to prevent field type mismatches
- Nested type support for complex API structures

## Testing Strategy

### Research Testing
- Generate chat completion types with various Progenitor configurations
- Compare generated types with async-openai equivalent types
- Validate serialization/deserialization compatibility
- Document configuration differences and their effects

### Type Testing
- Generated type serialization/deserialization
- Field presence and type validation
- Optional field handling
- JSON compatibility with OpenAI API format

### Test Organization
```
crates/openai/tests/
├── research/
│   └── async_openai_comparison_test.rs
└── types/
    ├── serialization_test.rs
    ├── chat_completions_test.rs
    ├── embeddings_test.rs
    └── other_endpoints_test.rs
```

## Build System Integration

### Cargo Workspace Configuration

```toml
# Root Cargo.toml
[workspace]
members = ["crates/*"]
resolver = "2"

[workspace.dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
reqwest = { version = "0.11", features = ["json"] }
tokio = { version = "1.0", features = ["full"] }
thiserror = "1.0"
progenitor = "0.x"
```

### Build Script Strategy

The OpenAI crate will include a `build.rs` script that:
1. Reads the OpenAPI specification
2. Configures Progenitor with research-determined flags
3. Generates types into appropriate modules
4. Applies post-processing for ergonomics

## Documentation Strategy

### API Documentation
- Comprehensive rustdoc comments for all public types
- Usage examples for serialization and deserialization
- Integration examples with popular HTTP clients
- Field documentation based on OpenAPI specification

### Developer Documentation
- Workspace setup instructions
- Type generation process explanation
- Research methodology and findings
- Configuration optimization guide

### Research Documentation
- Comparison methodology with async-openai
- Configuration decision rationale
- Type structure analysis
- Compatibility findings and recommendations